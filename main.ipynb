{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f9e9f88597e49bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T00:04:43.652468Z",
     "start_time": "2025-05-16T00:04:43.438093Z"
    }
   },
   "outputs": [],
   "source": [
    "from data_cleaning import clean_data\n",
    "from data_balancing import balance_data_sets\n",
    "from feature_selection import pca_selection, info_gain_selection, boruta_selection\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ad7eb",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0f9912c2bcf95c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T00:04:47.887314Z",
     "start_time": "2025-05-16T00:04:47.809784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "Class\n",
      "N    4161\n",
      "Y     838\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = clean_data() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d1e4e34ad3ce42",
   "metadata": {},
   "source": [
    "Data balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffb293daa5db4577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Class distribution after balancing:\n",
      "\n",
      "Under-sampling:\n",
      "Class\n",
      "N    838\n",
      "Y    838\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ROSE (RandomOverSampler approximation):\n",
      "Class\n",
      "Y    4161\n",
      "N    4161\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SMOTE:\n",
      "Class\n",
      "Y    4161\n",
      "N    4161\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "df_us, df_r, df_s = balance_data_sets(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e765c18",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3573147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PCA] Selected 1 components to retain 95.0% variance.\n",
      "[InfoGain] Top 10 features:\n",
      "['EMPLOY1', 'PNEUVAC4', 'CHCCOPD2', 'CHILDREN', 'BPHIGH4', 'ASTHMA3', 'DIABETE4', 'HTM4', 'FRUITJU2', 'WTKG3']\n",
      "[Boruta] Selected features:\n",
      "['EMPLOY1']\n",
      "[PCA] Selected 1 components to retain 95.0% variance.\n",
      "[InfoGain] Top 10 features:\n",
      "['EMPLOY1', 'WTKG3', 'MARITAL', 'CHILDREN', 'PNEUVAC4', 'BPHIGH4', 'HLTHPLN1', 'DIFFWALK', 'FLUSHOT7', 'PERSDOC2']\n",
      "[Boruta] Selected features:\n",
      "['GENHLTH', 'MARITAL', 'EMPLOY1', 'ALCDAY5', 'FRUIT2', 'FVGREEN1', 'VEGETAB2', 'PNEUVAC4', 'HTM4', 'WTKG3']\n",
      "[PCA] Selected 1 components to retain 95.0% variance.\n",
      "[InfoGain] Top 10 features:\n",
      "['HTM4', 'FVGREEN1', 'INCOME2', 'FRUIT2', 'VEGETAB2', 'EMPLOY1', 'GENHLTH', 'EDUCA', 'MARITAL', 'TETANUS1']\n",
      "[Boruta] Selected features:\n",
      "['GENHLTH', 'PERSDOC2', 'BPHIGH4', 'TOLDHI2', 'HAVARTH4', 'MARITAL', 'EDUCA', 'RENTHOM1', 'VETERAN3', 'EMPLOY1', 'INCOME2', 'DIFFWALK', 'SMOKE100', 'EXERANY2', 'FRUIT2', 'FVGREEN1', 'POTATOE1', 'FLUSHOT7', 'TETANUS1', 'PNEUVAC4', 'HIVTST7', 'HTM4', 'WTKG3']\n"
     ]
    }
   ],
   "source": [
    "feature_selected_sets = {}\n",
    "balanced_datasets = {\n",
    "    \"us\": df_us,\n",
    "    \"r\": df_r,\n",
    "    \"s\": df_s\n",
    "}\n",
    "\n",
    "for key, df in balanced_datasets.items():\n",
    "    X = df.drop(\"Class\", axis=1)\n",
    "    y = df[\"Class\"]\n",
    "    \n",
    "    # PCA\n",
    "    X_pca, _, _ = pca_selection(X)\n",
    "    df_pca = pd.DataFrame(X_pca)\n",
    "    df_pca[\"Class\"] = y.values\n",
    "    feature_selected_sets[f\"{key}_pca\"] = df_pca\n",
    "\n",
    "    # Info Gain\n",
    "    selected_info, _ = info_gain_selection(X, y, top_k=10)\n",
    "    df_info = df[selected_info + [\"Class\"]]\n",
    "    feature_selected_sets[f\"{key}_info\"] = df_info\n",
    "\n",
    "    # Boruta\n",
    "    selected_boruta, _ = boruta_selection(X, y)\n",
    "    df_boruta = df[selected_boruta + [\"Class\"]]\n",
    "    feature_selected_sets[f\"{key}_boruta\"] = df_boruta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb0f60c",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9f2186a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing [us_pca] with GaussianNB\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[ 40 128]\n",
      " [ 40 128]]\n",
      "\n",
      " Processing [us_info] with GaussianNB\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[126  42]\n",
      " [ 68 100]]\n",
      "\n",
      " Processing [us_boruta] with GaussianNB\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[114  54]\n",
      " [ 53 115]]\n",
      "\n",
      " Processing [r_pca] with GaussianNB\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[187 646]\n",
      " [178 654]]\n",
      "\n",
      " Processing [r_info] with GaussianNB\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[433 400]\n",
      " [186 646]]\n",
      "\n",
      " Processing [r_boruta] with GaussianNB\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[481 352]\n",
      " [228 604]]\n",
      "\n",
      " Processing [s_pca] with GaussianNB\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[211 622]\n",
      " [211 621]]\n",
      "\n",
      " Processing [s_info] with GaussianNB\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[318 515]\n",
      " [ 81 751]]\n",
      "\n",
      " Processing [s_boruta] with GaussianNB\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[461 372]\n",
      " [119 713]]\n"
     ]
    }
   ],
   "source": [
    "# ==================== NAIVE BAYES ====================\n",
    "for fs_name, df_fs in feature_selected_sets.items():\n",
    "    print(f\"\\n Processing [{fs_name}] with GaussianNB\")\n",
    "\n",
    "    # Preparing data\n",
    "    X = df_fs.drop(\"Class\", axis=1)\n",
    "    y = df_fs[\"Class\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # Train and fit\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, y_train)\n",
    "    y_pred = gnb.predict(X_test)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=gnb.classes_)\n",
    "    print(\"Classes order:\", list(gnb.classes_))\n",
    "    print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67054188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing [us_pca] with KNN Grid Search\n",
      "▶ Best params: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[76 92]\n",
      " [84 84]]\n",
      "\n",
      "Processing [us_info] with KNN Grid Search\n",
      "▶ Best params: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[90 78]\n",
      " [77 91]]\n",
      "\n",
      "Processing [us_boruta] with KNN Grid Search\n",
      "▶ Best params: {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[ 37 131]\n",
      " [ 14 154]]\n",
      "\n",
      "Processing [r_pca] with KNN Grid Search\n",
      "▶ Best params: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[584 249]\n",
      " [ 11 821]]\n",
      "\n",
      "Processing [r_info] with KNN Grid Search\n",
      "▶ Best params: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[584 249]\n",
      " [ 45 787]]\n",
      "\n",
      "Processing [r_boruta] with KNN Grid Search\n",
      "▶ Best params: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[532 301]\n",
      " [ 20 812]]\n",
      "\n",
      "Processing [s_pca] with KNN Grid Search\n",
      "▶ Best params: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[541 292]\n",
      " [331 501]]\n",
      "\n",
      "Processing [s_info] with KNN Grid Search\n",
      "▶ Best params: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[646 187]\n",
      " [100 732]]\n",
      "\n",
      "Processing [s_boruta] with KNN Grid Search\n",
      "▶ Best params: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[584 249]\n",
      " [ 26 806]]\n"
     ]
    }
   ],
   "source": [
    "# ==================== KNN ====================\n",
    "# Search grid\n",
    "knn_param_grid = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\"]\n",
    "}\n",
    "\n",
    "for fs_name, df_fs in feature_selected_sets.items():\n",
    "    print(f\"\\nProcessing [{fs_name}] with KNN Grid Search\")\n",
    "\n",
    "    # Split data\n",
    "    X = df_fs.drop(\"Class\", axis=1)\n",
    "    y = df_fs[\"Class\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # GridSearchCV\n",
    "    grid_knn = GridSearchCV(\n",
    "        estimator=KNeighborsClassifier(),\n",
    "        param_grid=knn_param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"f1_macro\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_knn.fit(X_train, y_train)\n",
    "\n",
    "    # Best model and predict\n",
    "    best_knn = grid_knn.best_estimator_\n",
    "    y_pred = best_knn.predict(X_test)\n",
    "\n",
    "    # Best parameters\n",
    "    print(\"▶ Best params:\", grid_knn.best_params_)\n",
    "\n",
    "    # Output\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=best_knn.classes_)\n",
    "    print(\"Classes order:\", list(best_knn.classes_))\n",
    "    print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "654d253f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing [us_pca] with Random Forest Grid Search\n",
      "▶ Best params: {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[ 65 103]\n",
      " [ 83  85]]\n",
      "\n",
      "Processing [us_info] with Random Forest Grid Search\n",
      "▶ Best params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[118  50]\n",
      " [ 50 118]]\n",
      "\n",
      "Processing [us_boruta] with Random Forest Grid Search\n",
      "▶ Best params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[127  41]\n",
      " [ 61 107]]\n",
      "\n",
      "Processing [r_pca] with Random Forest Grid Search\n",
      "▶ Best params: {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[644 189]\n",
      " [ 23 809]]\n",
      "\n",
      "Processing [r_info] with Random Forest Grid Search\n",
      "▶ Best params: {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[685 148]\n",
      " [ 31 801]]\n",
      "\n",
      "Processing [r_boruta] with Random Forest Grid Search\n",
      "▶ Best params: {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[751  82]\n",
      " [ 17 815]]\n",
      "\n",
      "Processing [s_pca] with Random Forest Grid Search\n",
      "▶ Best params: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[539 294]\n",
      " [321 511]]\n",
      "\n",
      "Processing [s_info] with Random Forest Grid Search\n",
      "▶ Best params: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[815  18]\n",
      " [162 670]]\n",
      "\n",
      "Processing [s_boruta] with Random Forest Grid Search\n",
      "▶ Best params: {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Classes order: ['N', 'Y']\n",
      "Confusion Matrix:\n",
      " [[817  16]\n",
      " [161 671]]\n"
     ]
    }
   ],
   "source": [
    "# ==================== Random Forest ====================\n",
    "# Search grid\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "for fs_name, df_fs in feature_selected_sets.items():\n",
    "    print(f\"\\nProcessing [{fs_name}] with Random Forest Grid Search\")\n",
    "\n",
    "    # Split data\n",
    "    X = df_fs.drop(\"Class\", axis=1)\n",
    "    y = df_fs[\"Class\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # GridSearchCV\n",
    "    grid_rf = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(),\n",
    "        param_grid=rf_param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"f1_macro\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_rf.fit(X_train, y_train)\n",
    "\n",
    "    # Best model and predict\n",
    "    best_rf = grid_rf.best_estimator_\n",
    "    y_pred = best_rf.predict(X_test)\n",
    "\n",
    "    # Best parameters\n",
    "    print(\"▶ Best params:\", grid_rf.best_params_)\n",
    "\n",
    "    # Output\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=best_rf.classes_)\n",
    "    print(\"Classes order:\", list(best_rf.classes_))\n",
    "    print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7debe647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing[us_pca] with XGB RandomizedSearchCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [16:55:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\core.py:729: UserWarning: [16:55:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Best params: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1.0}\n",
      "Labels order: [0='N', 1='Y']\n",
      "Confusion Matrix:\n",
      " [[77 91]\n",
      " [90 78]]\n",
      "\n",
      "Processing[us_info] with XGB RandomizedSearchCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [16:55:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Best params: {'subsample': 1.0, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1.0}\n",
      "Labels order: [0='N', 1='Y']\n",
      "Confusion Matrix:\n",
      " [[114  54]\n",
      " [ 53 115]]\n",
      "\n",
      "Processing[us_boruta] with XGB RandomizedSearchCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [16:55:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Best params: {'subsample': 1.0, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1.0}\n",
      "Labels order: [0='N', 1='Y']\n",
      "Confusion Matrix:\n",
      " [[127  41]\n",
      " [ 61 107]]\n",
      "\n",
      "Processing[r_pca] with XGB RandomizedSearchCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [16:55:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Best params: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1.0}\n",
      "Labels order: [0='N', 1='Y']\n",
      "Confusion Matrix:\n",
      " [[468 365]\n",
      " [327 505]]\n",
      "\n",
      "Processing[r_info] with XGB RandomizedSearchCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [16:55:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Best params: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1.0}\n",
      "Labels order: [0='N', 1='Y']\n",
      "Confusion Matrix:\n",
      " [[572 261]\n",
      " [172 660]]\n",
      "\n",
      "Processing[r_boruta] with XGB RandomizedSearchCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [16:55:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Best params: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1.0}\n",
      "Labels order: [0='N', 1='Y']\n",
      "Confusion Matrix:\n",
      " [[636 197]\n",
      " [162 670]]\n",
      "\n",
      "Processing[s_pca] with XGB RandomizedSearchCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [16:55:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Best params: {'subsample': 1.0, 'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1.0}\n",
      "Labels order: [0='N', 1='Y']\n",
      "Confusion Matrix:\n",
      " [[472 361]\n",
      " [363 469]]\n",
      "\n",
      "Processing[s_info] with XGB RandomizedSearchCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [16:55:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Best params: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1.0}\n",
      "Labels order: [0='N', 1='Y']\n",
      "Confusion Matrix:\n",
      " [[811  22]\n",
      " [157 675]]\n",
      "\n",
      "Processing[s_boruta] with XGB RandomizedSearchCV\n",
      "▶ Best params: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1.0}\n",
      "Labels order: [0='N', 1='Y']\n",
      "Confusion Matrix:\n",
      " [[818  15]\n",
      " [162 670]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ghl14\\anaconda3\\envs\\gpu-env\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [16:55:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
     ]
    }
   ],
   "source": [
    "# ==================== XGBoost ====================\n",
    "# Search grid\n",
    "xgb_param_dist = {\n",
    "    \"n_estimators\": [50, 100],       \n",
    "    \"max_depth\": [3, 5],             \n",
    "    \"learning_rate\": [0.1],          \n",
    "    \"subsample\": [1.0],              \n",
    "    \"colsample_bytree\": [1.0],       \n",
    "    \"gamma\": [0]                     \n",
    "}\n",
    "\n",
    "for fs_name, df_fs in feature_selected_sets.items():\n",
    "    print(f\"\\nProcessing[{fs_name}] with XGB RandomizedSearchCV\")\n",
    "\n",
    "    # Data preparing\n",
    "    X = df_fs.drop(\"Class\", axis=1)\n",
    "    y = df_fs[\"Class\"].map({\"N\":0,\"Y\":1})\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # Create model\n",
    "    model = XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        tree_method=\"gpu_hist\",\n",
    "        predictor=\"gpu_predictor\",\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "\n",
    "    # Random grid search\n",
    "    rand_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=xgb_param_dist,\n",
    "        n_iter=10,\n",
    "        cv=2,\n",
    "        scoring=\"f1_macro\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    rand_search.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "    best = rand_search.best_estimator_\n",
    "    print(\"▶ Best params:\", rand_search.best_params_)\n",
    "\n",
    "    # Output\n",
    "    y_pred = best.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    print(\"Labels order: [0='N', 1='Y']\")\n",
    "    print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0e8acab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing [us_pca] with MLP Grid Search\n",
      "▶ Best params: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'adaptive', 'max_iter': 300}\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[130  38]\n",
      " [124  44]]\n",
      "\n",
      "Processing [us_info] with MLP Grid Search\n",
      "▶ Best params: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 300}\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[168   0]\n",
      " [168   0]]\n",
      "\n",
      "Processing [us_boruta] with MLP Grid Search\n",
      "▶ Best params: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'max_iter': 300}\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[114  54]\n",
      " [ 53 115]]\n",
      "\n",
      "Processing [r_pca] with MLP Grid Search\n",
      "▶ Best params: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 300}\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[320 513]\n",
      " [320 512]]\n",
      "\n",
      "Processing [r_info] with MLP Grid Search\n",
      "▶ Best params: {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 300}\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[833   0]\n",
      " [832   0]]\n",
      "\n",
      "Processing [r_boruta] with MLP Grid Search\n",
      "▶ Best params: {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 300}\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[ 12 821]\n",
      " [  3 829]]\n",
      "\n",
      "Processing [s_pca] with MLP Grid Search\n",
      "▶ Best params: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 300}\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[471 362]\n",
      " [448 384]]\n",
      "\n",
      "Processing [s_info] with MLP Grid Search\n",
      "▶ Best params: {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 300}\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[500 333]\n",
      " [153 679]]\n",
      "\n",
      "Processing [s_boruta] with MLP Grid Search\n",
      "▶ Best params: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 300}\n",
      "Classes order: [np.str_('N'), np.str_('Y')]\n",
      "Confusion Matrix:\n",
      " [[827   6]\n",
      " [829   3]]\n"
     ]
    }
   ],
   "source": [
    "# ==================== MLP ====================\n",
    "# Search grid\n",
    "mlp_param_grid = {\n",
    "    \"hidden_layer_sizes\": [(50,), (100,), (100, 50)],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"alpha\": [0.0001, 0.001],\n",
    "    \"learning_rate\": [\"constant\", \"adaptive\"],\n",
    "    \"max_iter\": [300]\n",
    "}\n",
    "\n",
    "# MLP Grid Search for all feature selections\n",
    "for fs_name, df_fs in feature_selected_sets.items():\n",
    "    print(f\"\\nProcessing [{fs_name}] with MLP Grid Search\")\n",
    "\n",
    "    # Split data\n",
    "    X = df_fs.drop(\"Class\", axis=1)\n",
    "    y = df_fs[\"Class\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.2,\n",
    "        stratify=y,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # GridSearchCV\n",
    "    grid_mlp = GridSearchCV(\n",
    "        estimator=MLPClassifier(),\n",
    "        param_grid=mlp_param_grid,\n",
    "        cv=2,\n",
    "        scoring=\"f1_macro\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_mlp.fit(X_train, y_train)\n",
    "\n",
    "    # Best model and predict\n",
    "    best_mlp = grid_mlp.best_estimator_\n",
    "    y_pred = best_mlp.predict(X_test)\n",
    "\n",
    "    # Print best parameter\n",
    "    print(\"▶ Best params:\", grid_mlp.best_params_)\n",
    "\n",
    "    # Output\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=best_mlp.classes_)\n",
    "    print(\"Classes order:\", list(best_mlp.classes_))\n",
    "    print(\"Confusion Matrix:\\n\", cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
